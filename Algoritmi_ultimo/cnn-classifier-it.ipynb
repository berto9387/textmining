{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import librerie"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import word_tokenize \nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport seaborn as sns\nfrom lime import lime_text\nimport unicodedata\nimport pandas as pd\nfrom string import punctuation\nimport numpy as np\nimport torch\nfrom nltk.tokenize import word_tokenize\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch import nn\nfrom torch import optim\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nimport time\nimport random\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"language=\"italian\"\nlanguage_w=\"../input/fasttext-aligned-word-vectors/wiki.in.align.vec\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text=\"question_description\"\n#review=\"ministry\"\n#n_top_class=35\n#path_db=\"/kaggle/input/rajyasabha/rajyasabha_q*.{}\"\n#import glob\n#import pandas as pd\n#extension = 'csv'\n#all_filenames = [i for i in glob.glob(path_db.format(extension))]\n#combine all files in the list\n#df = pd.concat([pd.read_csv(f,encoding='latin1') for f in all_filenames ])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text=\"testo\"\nreview=\"cap_maj_master\"\npath_db=\"../input/ciao9cci/politica.xlsx\"\nn_top_class=35\ndf = pd.read_excel(path_db, sheet_name=\"Foglio1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_class=df.groupby(review).count()[[text]]\ntop_class=top_class.sort_values(by=[text], ascending=False).head(n_top_class)\ntop_class=top_class.apply(list).reset_index()\ntop_class = [d for d in top_class[review]]\nprint(top_class)\n\ndf=df.loc[df[review].isin(top_class)]\nprint(f'Found {len(df)} texts.')\nprint(f'{df[review].isnull().sum()} document(s) with no classification removed')\ndf=df[pd.notnull(df[review])]\n\ndf = df[df[text].str.split().str.len().gt(5)]\n\nprint(f'{df[text].isnull().sum()} document(s) with no text removed')\ndf=df[pd.notnull(df[text])]\n\nle = preprocessing.LabelEncoder()\nle.fit(df[review])\ndf[review]=le.transform(df[review])\nclasses = [int(c) for c in df[review].values]\ndocuments = [d for d in df[text]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Import dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.bincount(classes)\nx = np.arange(len(y))\nprint(len(y))\nfig, ax = plt.subplots(figsize=(15,22))\nplt.bar(x, y,width=0.7)\nax.set_xticks(x)\nax.set_aspect('auto')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessor(text):\n    text = re.sub('<[^>]*>', ' ', str(text))\n    #text = re.sub(r'[^\\w\\s]',\" \", text)\n    text=re.sub('\\d+',' ',str(text))\n    text=re.sub('[ﾫﾻ]','',str(text))\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n                           str(text))\n    text = (re.sub('[\\W]+', ' ', text.lower().strip()) + ' ' +\n            ' '.join(emoticons).replace('-', ''))\n    return text\n\ndef strip_accents(text):\n    \"\"\"\n    Strip accents from input String.\n\n    :param text: The input string.\n    :type text: String.\n\n    :returns: The processed String.\n    :rtype: String.\n    \"\"\"\n    try:\n        text = unicode(text, 'utf-8')\n    except (TypeError, NameError): # unicode is a default on python 3 \n        pass\n    text = unicodedata.normalize('NFD', text)\n    text = text.encode('ascii', 'ignore')\n    text = text.decode(\"utf-8\")\n    return str(text)\n\nstop=set(stopwords.words(language))\n\ndef tokenizer_porter(text):\n    word_tokens = word_tokenize(text)\n    stemmer = SnowballStemmer(language, ignore_stopwords=True)\n    return [stemmer.stem(word) for word in word_tokens]\n  \n\ndef tokenizer(text):\n    stop=set(stopwords.words(language))\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w in stop]\n    filtered_sentence = [w for w in filtered_sentence if len(w)>3]\n    return filtered_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_words_documents(documents):\n    tokenized = documents = [tokenizer(strip_accents(preprocessor(document))) \n                              for document in documents]\n    all_text = []\n    for tokens in tokenized:\n        for t in tokens:\n            all_text.append(t)\n    return tokenized, set(all_text)\n\ndocuments, vocab = split_words_documents(documents)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.max([len(x) for x in documents]))\nprint(np.mean([len(x) for x in documents]))\nquant=np.quantile([len(x) for x in documents],.75)\nprint(quant)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocaboli=set(line.strip() for line in open('../input/prova2/prova.txt'))\nvocaboli_more=vocaboli.union(vocab)\nprint(\"Aggiunte \",len(vocaboli_more)-len(vocaboli),\"/\",len(vocab),\" parole\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dictionaries(words):\n    word_to_int_dict = {w:i+1 for i,w in enumerate(words)}\n    int_to_word_dict = {i:w for w,i in word_to_int_dict.items()}\n    return word_to_int_dict, int_to_word_dict\nword_to_int_dict, int_to_word_dict = create_dictionaries(vocaboli)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_text(tokenized_documents,seq_length):\n    documents = []\n    length=[]\n    for document in tokenized_documents:\n        if len(document) >= seq_length:\n            documents.append(document[:seq_length])\n            length.append(seq_length)\n        else:\n            length.append(len(document))\n            documents.append(document+['']*(seq_length-len(document)))\n    return np.array(documents),np.array(length)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_to_word_dict[0]=''\nword_to_int_dict['']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_pretrained_vectors(word2idx, fname):\n    \"\"\"Load pretrained vectors and create embedding layers.\n    \n    Args:\n        word2idx (Dict): Vocabulary built from the corpus\n        fname (str): Path to pretrained vector file\n\n    Returns:\n        embeddings (np.array): Embedding matrix with shape (N, d) where N is\n            the size of word2idx and d is embedding dimension\n    \"\"\"\n\n    print(\"Loading pretrained vectors...\")\n    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n    n, d = map(int, fin.readline().split())\n\n    # Initilize random embeddings\n    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n    embeddings[word2idx['']] = np.zeros((d,))\n\n    # Load pretrained vectors\n    count = 0\n    for line in tqdm(fin):\n        tokens = line.rstrip().split(' ')\n        word = tokens[0]\n        if word in word2idx:\n            count += 1\n            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.double)\n\n    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n\n    return embeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load pretrained vectors\nprint(\"Tokenizing...\\n\")\nembeddings = load_pretrained_vectors(word_to_int_dict, language_w)\nembeddings = torch.tensor(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#DEVICE='cpu'\nSEED = 2019\n\n#Torch\ntorch.manual_seed(SEED)\n\n#Cuda algorithms\ntorch.backends.cudnn.deterministic = True ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sort_batch(X,lengths,y):\n    lengths, indx = lengths.sort(dim=0, descending=True)\n    X = X[indx]\n    y = y[indx]\n    return X,lengths, y ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data_loader(train_c,train_len, valid_c, valid_len, train_l,valid_l,batch_size):\n    x_train = torch.tensor(train_c, dtype=torch.long,device=DEVICE)\n    x_train_len = torch.tensor(train_len, dtype=torch.long,device=DEVICE)\n    y_train = torch.tensor(train_l, dtype=torch.long, device=DEVICE)\n    x_cv = torch.tensor(valid_c, dtype=torch.long, device=DEVICE)\n    x_cv_len = torch.tensor(valid_len, dtype=torch.long, device=DEVICE)\n    y_cv = torch.tensor(valid_l, dtype=torch.long, device=DEVICE)\n    # Create Torch datasets\n    train = torch.utils.data.TensorDataset(x_train,x_train_len, y_train)\n    valid = torch.utils.data.TensorDataset(x_cv,x_cv_len, y_cv)\n    # Create Data Loaders\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n    return train_loader, valid_loader\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_graph(train_loss, valid_loss):\n    fig = plt.figure(figsize=(10,8))\n    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n\n    # find position of lowest validation loss\n    minposs = valid_loss.index(min(valid_loss))+1 \n    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    #plt.ylim(0, 0.5) # consistent scale\n    #plt.xlim(0, len(train_loss)+1) # consistent scale\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\n#https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print            \n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationCNN(nn.Module):\n    \n    def __init__(self, \n                 pretrained_embedding=None,\n                 freeze_embedding=False,\n                 n_vocab=None, \n                 n_embed=300,\n                 n_filters=100, \n                 n_output=1, \n                 filter_sizes=[2,3,4], \n                 dropout = 0.8,\n                 pad_idx=0.0):\n        super().__init__()\n        # Embedding layer\n        if pretrained_embedding is not None:\n            self.n_vocab, self.n_embed = pretrained_embedding.shape\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n                                                          freeze=freeze_embedding)\n        \n        \n         \n        self.dropout = nn.Dropout(dropout)\n        self.convs = nn.ModuleList([\n                                    nn.Conv1d(in_channels = self.n_embed, \n                                              out_channels = n_filters, \n                                              kernel_size = fs) \n                                    for fs in filter_sizes\n                                    ])\n        \n        \n        self.fc1 = nn.Linear(len(filter_sizes) * n_filters, n_filters)\n        self.fc2 = nn.Linear(n_filters, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.relu = nn.ReLU()\n        \n\n        \n        \n    def forward(self, text,len_text):\n        \n        emb = self.embedding(text)\n        emb=emb.transpose(2,1)\n        conved = [F.relu(c(emb)) for c in self.convs] \n        #al max_pool1d diamo come parametro il filter size\n        pooled = [F.max_pool1d(c, c.shape[2]).squeeze(2) for c in conved]\n        concat = self.dropout(torch.cat(pooled, dim = 1))\n        out=self.fc1(concat)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, data_loader, criterion):\n    model.eval()\n    val_accuracy = []\n    val_loss = []\n    with torch.no_grad():\n        for i, (x_batch,len_batch, y_batch) in enumerate(data_loader):\n            #x_batch,len_batch, y_batch=sort_batch(x_batch,len_batch, y_batch)\n            logits= model(x_batch,len_batch)\n            loss = criterion(logits, y_batch)\n            val_loss.append(loss.item())\n            \n            _, preds = torch.max(logits, 1)\n            accuracy = (preds == y_batch).cpu().numpy().mean() * 100\n            val_accuracy.append(accuracy)\n        val_accuracy = np.mean(val_accuracy)\n        return val_loss, val_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, optimizer,criterion, train_loader, val_loader=None, patience=7, epochs=10):\n    print(\"Start training...\\n\")\n    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n    print(\"-\"*60)\n    best_accuracy=0\n    # to track the training loss as the model trains\n    train_losses = []\n    # to track the validation loss as the model trains\n    valid_losses = []\n    # to track the average training loss per epoch as the model trains\n    avg_train_losses = []\n    # to track the average validation loss per epoch as the model trains\n    avg_valid_losses = []\n    \n    # initialize the early_stopping object\n    early_stopping = EarlyStopping(patience=patience, verbose=True)\n    \n    for epoch in range(1, epochs + 1):\n        start_time = time.time()\n        t0_epoch = time.time()\n        total_loss = 0\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for i, (x_batch,len_batch, y_batch) in enumerate(train_loader):\n            #x_batch,len_batch, y_batch=sort_batch(x_batch,len_batch, y_batch)\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            y_pred= model(x_batch,len_batch)\n            # calculate the loss\n            loss = criterion(y_pred, y_batch)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # record training loss\n            train_losses.append(loss.item())\n            \n        ######################    \n        # validate the model #\n        ###################### \n        valid_losses, val_accuracy = evaluate(model, val_loader,criterion)\n        \n        # calculate average loss over an epoch\n        train_loss = np.average(train_losses)\n        valid_loss = np.average(valid_losses)\n        avg_train_losses.append(train_loss)\n        avg_valid_losses.append(valid_loss)\n        \n        time_elapsed = time.time() - t0_epoch\n        print(f\"{epoch :^7} | {train_loss:^12.6f} | {valid_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n        \n        # clear lists to track next epoch\n        train_losses = []\n        valid_losses = []\n        \n        # early_stopping needs the validation loss to check if it has decresed, \n        # and if it has, it will make a checkpoint of the current model\n        early_stopping(valid_loss, model)\n        \n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n        \n        \n    print(\"\\n\")\n    \n    plot_graph(avg_train_losses, avg_valid_losses)\n    model.load_state_dict(torch.load('checkpoint.pt'))\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pytorch_predict(model, test_loader):\n    '''\n    Make prediction from a pytorch model \n    '''\n    # set model to evaluate model\n    model.eval()\n    labels=[]\n    with torch.no_grad():\n        for (text,length, label) in test_loader: \n            #text,length, label=sort_batch(text,length, label)\n            outputs = model(text,length)\n            _, preds = torch.max(outputs, 1)\n            for pred in preds:\n                labels.append(pred.item())\n    \n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\noutput_dim = len(np.unique(classes))\nnumber_of_filters = 100\nfilter_sizes = [1,2,3]\ndropout_pc = 0.5\nn_epochs = 100\nnfold=10\npatience=5\nlr = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\n\ny=np.array(classes)\ndocuments=np.array(documents)\nkfold = StratifiedKFold(n_splits=nfold).split(documents, y)\n\naccuracys = []\nscores= []\nmetriche = np.zeros((nfold,4,output_dim))\n\n#target_names=le.inverse_transform(target_names)\n\nfor k, (train_ids, test_ids) in enumerate(kfold):\n    \n    padded_sentences_train,lenght_train = pad_text(documents[train_ids], seq_length = int(quant))\n    padded_sentences_test,lenght_test = pad_text(documents[test_ids], seq_length = int(quant))\n    \n    encoded_sentences_train = np.array([[word_to_int_dict[word] if word in word_to_int_dict else 0 for word in content ] for content in padded_sentences_train])\n    encoded_sentences_test  = np.array([[word_to_int_dict[word] if word in word_to_int_dict else 0 for word in content ] for content in padded_sentences_test])\n    \n    print(\"train:\",encoded_sentences_train.shape,\"len:\",lenght_train.size, \"train_y:\",y[train_ids].size)\n    print(\"test:\",encoded_sentences_test.shape,\"len:\",lenght_test.size)\n    \n    \n    \n    train_loader, val_loader=create_data_loader(encoded_sentences_train,lenght_train,\n                                                encoded_sentences_test,lenght_test,\n                                                y[train_ids],y[test_ids],batch_size)\n    \n    \n    model = ClassificationCNN(\n                        pretrained_embedding=embeddings, \n                        n_output=output_dim,\n                        filter_sizes=filter_sizes,\n                        dropout=dropout_pc,\n                        n_filters=number_of_filters)\n    model=model.double()\n    loss_fn = nn.CrossEntropyLoss(reduction='sum').to(DEVICE)\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=lr,weight_decay=0.01)\n    model.to(DEVICE)\n    model=train(model,optimizer,loss_fn,train_loader,val_loader,patience,n_epochs)\n    \n    \n    y_pred=pytorch_predict(model,val_loader)\n    \n    y_true=y[test_ids]\n    \n    target_names=np.unique(y[train_ids])\n    accuracys.append(metrics.accuracy_score(y_true, y_pred))\n    score=precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=target_names, average=\"weighted\")\n    scores.append(score[0:3])\n    print('--------------- Fold: %2d ---------------------'% (k+1))\n    print()\n    target_names = list(map(str,target_names))\n    print(metrics.classification_report(y_true, y_pred, target_names=target_names))\n    dizionario=metrics.classification_report(y_true, y_pred, target_names=target_names,output_dict=True)\n    for k_d,(m_id, m_info) in enumerate(dizionario.items()):\n        if k_d<output_dim:\n            for j_d,key in enumerate(m_info):\n                metriche[k,j_d,k_d]=m_info[key]\n        else:\n            break\n    \n    conf_mat = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(10,10))\n    sns.heatmap(conf_mat, annot=True, fmt='d',\n                xticklabels=target_names , yticklabels=target_names )\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.show()\n    print()\n\narr = np.array(scores)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Overall results of the cross-validation procedure\")\nprint()\nprint(f\"{'Class':^7} | {'precision':^9}{'':^6} | {'recall':^10}{'':^5} | {'f1-measure':^6}{'':^5} | {'support':^9}\")\nfor i in range(output_dim):\n    print(f\"{i :^7} | {np.mean(metriche[:,0,i])*100:^5.2f} +/-{np.std(metriche[:,0,i])*100:^6.2f} | {np.mean(metriche[:,1,i])*100:^5.2f} +/-{np.std(metriche[:,1,i])*100:^6.2f} | {np.mean(metriche[:,2,i])*100:^5.2f} +/-{np.std(metriche[:,2,i])*100:^6.2f} | {np.mean(metriche[:,3,i]):^9.2f}\")\nprint()\nprint('\\nCV accuracy: %.2f +/- %.2f max: %.2f' % (np.mean(accuracys)*100, np.std(accuracys)*100,np.max(accuracys)*100))\nprint('\\nCV precision: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,0])*100, np.std(arr[:,0])*100,np.max(arr[:,0])*100))\nprint('\\nCV recall: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,1])*100, np.std(arr[:,1])*100,np.max(arr[:,1])*100))\nprint('\\nCV f1: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,2])*100, np.std(arr[:,2])*100,np.max(arr[:,2])*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}