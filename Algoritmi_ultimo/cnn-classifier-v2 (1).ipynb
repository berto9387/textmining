{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import librerie"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import word_tokenize \nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport seaborn as sns\nfrom lime import lime_text\nimport unicodedata\nimport pandas as pd\nfrom string import punctuation\nimport numpy as np\nimport torch\nfrom nltk.tokenize import word_tokenize\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch import nn\nfrom torch import optim\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nimport time\nimport random\nimport torch.nn.functional as F","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"language=\"english\"\nlanguage_w=\"../input/fasttext-aligned-word-vectors/wiki.en.align.vec\"\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text=\"question_description\"\nreview=\"ministry\"\nn_top_class=35\npath_db=\"/kaggle/input/rajyasabha/rajyasabha_q*.{}\"\nimport glob\nimport pandas as pd\nextension = 'csv'\nall_filenames = [i for i in glob.glob(path_db.format(extension))]\n#combine all files in the list\ndf = pd.concat([pd.read_csv(f,encoding='latin1') for f in all_filenames ])\n\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text=\"testo\"\n#review=\"cap_maj_master\"\n#path_db=\"../input/ciao9cci/politica.xlsx\"\n#n_top_class=35\n#df = pd.read_excel(path_db, sheet_name=\"Foglio1\")","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_class=df.groupby(review).count()[[text]]\ntop_class=top_class.sort_values(by=[text], ascending=False).head(n_top_class)\ntop_class=top_class.apply(list).reset_index()\ntop_class = [d for d in top_class[review]]\nprint(top_class)\n\ndf=df.loc[df[review].isin(top_class)]\nprint(f'Found {len(df)} texts.')\nprint(f'{df[review].isnull().sum()} document(s) with no classification removed')\ndf=df[pd.notnull(df[review])]\n\ndf = df[df[text].str.split().str.len().gt(5)]\n\nprint(f'{df[text].isnull().sum()} document(s) with no text removed')\ndf=df[pd.notnull(df[text])]\n\nle = preprocessing.LabelEncoder()\nle.fit(df[review])\ndf[review]=le.transform(df[review])\nclasses = [int(c) for c in df[review].values]\ndocuments = [d for d in df[text]]","execution_count":12,"outputs":[{"output_type":"stream","text":"['HOME AFFAIRS', 'FINANCE', 'HEALTH AND FAMILY WELFARE', 'RAILWAYS', 'HUMAN RESOURCE DEVELOPMENT', 'AGRICULTURE', 'PETROLEUM AND NATURAL GAS', 'CIVIL AVIATION', 'CONSUMER AFFAIRS, FOOD AND PUBLIC DISTRIBUTION', 'LABOUR AND EMPLOYMENT', 'DEFENCE', 'EXTERNAL AFFAIRS', 'COMMUNICATION AND INFORMATION TECHNOLOGY', 'POWER', 'ROAD TRANSPORT & HIGH WAYS', 'ENVIRONMENT AND FORESTS', 'COMMERCE AND INDUSTRY', 'WOMEN AND CHILD DEVELOPMENT', 'RURAL DEVELOPMENT', 'COAL', 'LAW & JUSTICE', 'CHEMICALS AND FERTILIZERS', 'AGRICULTURE  AND FARMERS WELFARE', 'SOCIAL JUSTICE AND EMPOWERMENT', 'URBAN DEVELOPMENT', 'ENVIRONMENT, FOREST  AND CLIMATE CHANGE', 'COMMERCE AND INDUSTRY  ', 'INFORMATION AND BROADCASTING', 'TOURISM', 'CULTURE', 'PERSONNEL,PUBLIC GRIEVANCES AND PENSIONS', 'DRINKING WATER AND SANITATION', 'NEW AND RENEWABLE ENERGY', 'YOUTH AFFAIRS AND SPORTS', 'WATER RESOURCES']\nFound 73756 texts.\n0 document(s) with no classification removed\n0 document(s) with no text removed\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Import dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.bincount(classes)\nx = np.arange(len(y))\nprint(len(y))\nfig, ax = plt.subplots(figsize=(15,22))\nplt.bar(x, y,width=0.7)\nax.set_xticks(x)\nax.set_aspect('auto')\nplt.show()\n","execution_count":13,"outputs":[{"output_type":"stream","text":"35\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x1584 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA3MAAATLCAYAAAAwd+7sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdUYjm973X8c/3ZA41qMWWbkLYbZle5MI2cHpoCIFeeSo2sAfTm0outLkoLJSCPSDIxDsvAnMl0osWikq2qMSAHhrOWjVEiwjh1K1Wa9pTGuycNiQ0a1WsN4HGnxf7L8xJp9mZ3TmZ/ey+XvDw/J/f/H/P/B7m6s3v+f9n1loBAACgy2+c9QIAAAA4OTEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBo56wXcCMf+MAH1u7u7lkvAwAA4Ex8+9vf/h9rrXNvH7/tY253dzdXr14962UAAACciZn546PGfc0SAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAArtnPUCAOCs7e5duem5B/sXT3ElAHB8duYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAK7Zz1AgC48+zuXbnpuQf7F09xJQBw57IzBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUGjnrBcAAMe1u3flpuce7F88xZUAwNmzMwcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQKFjxdzMHMzMd2fmOzNzdRt7/8y8MDM/3J7fd+j8p2bmlZn5wcx86tD4x7f3eWVmvjQzc/ofCQAA4M53kp25v7TW+tha6+Ht9V6SF9daDyZ5cXudmflIkieSfDTJY0m+PDP3bHO+kuRSkge3x2O3/hEAAADuPrfyNcvHk1zeji8n+fSh8WfXWm+utX6U5JUkj8zMA0neu9Z6aa21knzt0BwAAABO4Lgxt5L8m5n59sxc2sbuX2u9niTb833b+PkkPzk099Vt7Px2/PZxAAAATmjnmOd9Yq312szcl+SFmfmjdzj3qOvg1juM/+obXA/GS0nyoQ996JhLBAAAuHsca2durfXa9vxGkt9P8kiSn25fncz2/MZ2+qtJPnho+oUkr23jF44YP+r3fXWt9fBa6+Fz584d/9MAAADcJW4YczPzZ2fmz//yOMlfSfLfkjyf5MnttCeTfH07fj7JEzPznpn5cK7f6ORb21cxfz4zj253sfzsoTkAAACcwHG+Znl/kt/f/ovATpJ/utb6VzPzH5M8NzOfS/LjJJ9JkrXWyzPzXJLvJflFki+std7a3uvzSZ5Jcm+Sb2wPAAAATuiGMbfW+u9JfuuI8Z8l+eSvmfN0kqePGL+a5KGTLxMAAIDDbuVfEwAAAHBGxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUGjnrBcAAMDtZXfvyk3PPdi/eIorAd6JnTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAArtnPUCAOBOtLt35ZbmH+xfPKWVAHCnsjMHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhY4dczNzz8z855n5g+31+2fmhZn54fb8vkPnPjUzr8zMD2bmU4fGPz4z391+9qWZmdP9OAAAAHeHk+zMfTHJ9w+93kvy4lrrwSQvbq8zMx9J8kSSjyZ5LMmXZ+aebc5XklxK8uD2eOyWVg8AAHCXOlbMzcyFJBeT/INDw48nubwdX07y6UPjz6613lxr/SjJK0kemZkHkrx3rfXSWmsl+dqhOQAAAJzAcXfm/n6Sv53k/x0au3+t9XqSbM/3bePnk/zk0HmvbmPnt+O3jwMAAHBCN4y5mfndJG+stb59zPc86jq49Q7jR/3OSzNzdWauXrt27Zi/FgAA4O5xnJ25TyT5qzNzkOTZJL8zM/84yU+3r05me35jO//VJB88NP9Ckte28QtHjP+KtdZX11oPr7UePnfu3Ak+DgAAwN3hhjG31npqrXVhrbWb6zc2+bdrrb+e5PkkT26nPZnk69vx80memJn3zMyHc/1GJ9/avor585l5dLuL5WcPzQEAAOAEdm5h7n6S52bmc0l+nOQzSbLWenlmnkvyvSS/SPKFtdZb25zPJ3kmyb1JvrE9AAAAOKETxdxa65tJvrkd/yzJJ3/NeU8nefqI8atJHjrpIgEAAPiTTvJ/5gAAALhNiDkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAK3TDmZubPzMy3Zua/zMzLM/N3t/H3z8wLM/PD7fl9h+Y8NTOvzMwPZuZTh8Y/PjPf3X72pZmZP52PBQAAcGc7zs7cm0l+Z631W0k+luSxmXk0yV6SF9daDyZ5cXudmflIkieSfDTJY0m+PDP3bO/1lSSXkjy4PR47xc8CAABw17hhzK3r/u/28je3x0ryeJLL2/jlJJ/ejh9P8uxa68211o+SvJLkkZl5IMl711ovrbVWkq8dmgMAAMAJHOuauZm5Z2a+k+SNJC+stf4wyf1rrdeTZHu+bzv9fJKfHJr+6jZ2fjt++/hRv+/SzFydmavXrl07yecBAAC4Kxwr5tZab621PpbkQq7vsj30DqcfdR3ceofxo37fV9daD6+1Hj537txxlggAAHBXOdHdLNda/zvJN3P9Wrefbl+dzPb8xnbaq0k+eGjahSSvbeMXjhgHAADghI5zN8tzM/MXtuN7k/zlJH+U5PkkT26nPZnk69vx80memJn3zMyHc/1GJ9/avor585l5dLuL5WcPzQEAAOAEdo5xzgNJLm93pPyNJM+ttf5gZl5K8tzMfC7Jj5N8JknWWi/PzHNJvpfkF0m+sNZ6a3uvzyd5Jsm9Sb6xPQAAADihG8bcWuu/JvntI8Z/luSTv2bO00mePmL8apJ3ut4OAACAYzjRNXMAAADcHsQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFNo56wW02t27ctNzD/YvnuJKAACAu5GdOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACu2c9QIAAO50u3tXbnruwf7FU1wJcCexMwcAAFBIzAEAABQScwAAAIVcM8ctcQ0AAACcDTtzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUGjnrBcAvLt2967c0vyD/YuntBIAAG6FnTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCO2e9AADg7O3uXbml+Qf7F09pJQAcl505AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBC7mYJ3NZu5Q577q4HANzJ7MwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAU2jnrBQBwdnb3rtz03IP9i6e4EgDgpOzMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUGjnrBcAHG1378otzT/Yv3hKKwEA4HZkZw4AAKCQmAMAACgk5gAAAArdMOZm5oMz8+9m5vsz8/LMfHEbf//MvDAzP9ye33dozlMz88rM/GBmPnVo/OMz893tZ1+amfnT+VgAAAB3tuPszP0iyd9aa/3FJI8m+cLMfCTJXpIX11oPJnlxe53tZ08k+WiSx5J8eWbu2d7rK0kuJXlwezx2ip8FAADgrnHDmFtrvb7W+k/b8c+TfD/J+SSPJ7m8nXY5yae348eTPLvWenOt9aMkryR5ZGYeSPLetdZLa62V5GuH5gAAAHACJ7pmbmZ2k/x2kj9Mcv9a6/XkevAluW877XySnxya9uo2dn47fvv4Ub/n0sxcnZmr165dO8kSAQAA7grHjrmZ+XNJ/nmS31tr/Z93OvWIsfUO4786uNZX11oPr7UePnfu3HGXCAAAcNc4VszNzG/mesj9k7XWv9iGf7p9dTLb8xvb+KtJPnho+oUkr23jF44YBwAA4ISOczfLSfIPk3x/rfX3Dv3o+SRPbsdPJvn6ofEnZuY9M/PhXL/Rybe2r2L+fGYe3d7zs4fmAAAAcAI7xzjnE0n+RpLvzsx3trG/k2Q/yXMz87kkP07ymSRZa708M88l+V6u3wnzC2utt7Z5n0/yTJJ7k3xjewAAAHBCN4y5tdZ/yNHXuyXJJ3/NnKeTPH3E+NUkD51kgQAAAPyqE93NEgAAgNvDcb5mCQDAbWh378pNzz3Yv3iKKwHOgp05AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQjtnvQAAAO4Ou3tXbnruwf7FU1wJ3BnszAEAABQScwAAAIXEHAAAQCExBwAAUMgNUABOkYv7AYB3i505AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKLRz1guAd8vu3pVbmn+wf/GUVgIAALfOzhwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFNo56wUAAMCt2N27ctNzD/YvnuJKOK5b+Zsl/m6/ZGcOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEL+aTi3Hf9EEgAAbszOHAAAQCExBwAAUEjMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQCExBwAAUGjnrBcAANy5dveu3NL8g/2Lp7QSgDuPnTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCO2e9AN4du3tXbnruwf7FU1wJAABwGuzMAQAAFBJzAAAAhcQcAABAITEHAABQSMwBAAAUEnMAAACFxBwAAEAhMQcAAFBIzAEAABQScwAAAIXEHAAAQKGds14Af9Lu3pWbnnuwf/EUVwIAANzO7MwBAAAUEnMAAACFfM0SAACO4PIXbnd25gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQmIOAACgkJgDAAAoJOYAAAAKiTkAAIBCYg4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJCYAwAAKCTmAAAACok5AACAQjtnvQAAAODW7e5duem5B/sXT3ElvFvszAEAABQScwAAAIXEHAAAQCExBwAAUEjMAQAAFBJzAAAAhfxrAoACbjcNALydnTkAAIBCdubgFt3Kjkli1wQAgJtjZw4AAKCQmAMAACgk5gAAAAqJOQAAgEJiDgAAoJC7WQJAEXfQBeCX7MwBAAAUEnMAAACFxBwAAEAh18wBAMC76FaufXXdK4fZmQMAACgk5gAAAAqJOQAAgEKumQNOhe//AwC8u+zMAQAAFBJzAAAAhcQcAABAITEHAABQyA1QAAA2buYENLEzBwAAUEjMAQAAFBJzAAAAhW54zdzM/KMkv5vkjbXWQ9vY+5P8syS7SQ6S/LW11v/afvZUks8leSvJ31xr/ett/ONJnklyb5J/meSLa611uh8H4HhcFwMAtDvOztwzSR5729hekhfXWg8meXF7nZn5SJInknx0m/Plmblnm/OVJJeSPLg93v6eAAAAHNMNY26t9e+T/M+3DQNU+BoAABGqSURBVD+e5PJ2fDnJpw+NP7vWenOt9aMkryR5ZGYeSPLetdZL227c1w7NAQAA4IRu9pq5+9daryfJ9nzfNn4+yU8OnffqNnZ+O377OAAAADfhtG+AMkeMrXcYP/pNZi7NzNWZuXrt2rVTWxwAAMCd4mb/afj/b+9eY2Ur6zOAP/+CqOANRVoUWtEg0RiLSImtihaMBWuwtqHB2JZGjalRqza2xdBYjTHx2vZLo6Fq23hBqVc0WqG2aj/UCyAoCCgqylEEbdNqayKibz/MOu32ODOHs9e7h/Pi75dM9szsfZ79ntnz32uemTVr31hVR7TWbph2obxpun5XkqO2fN2RSb4xXX/kkuuXaq2dm+TcJDnhhBMcJAUA+DFzDmKUOJARcPuw3VfmLkhy1nT+rCTv23L9mVV1x6o6OosDnXxq2hXzu1X1iKqqJL+35d8AAACwj27NnyY4L8ljkxxWVbuS/HmSVyQ5v6qenuRrSc5IktbalVV1fpLPJ7klybNbaz+cop6V///TBB+aTgAAAGzDXstca+0pKz51yoqvf3mSly+5/uIkD9mn1QEAALBU7wOgAAAAsAHbPQAKAADAfuWn7eBIyhwAALDUT1s5Go3dLAEAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAANS5gAAAAakzAEAAAxImQMAABiQMgcAADAgZQ4AAGBAyhwAAMCAlDkAAIABKXMAAAADUuYAAAAGpMwBAAAMSJkDAAAYkDIHAAAwIGUOAABgQMocAADAgJQ5AACAASlzAAAAA1LmAAAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEAbL3NVdWpVXVNV11bV2Zv+/gAAALcHGy1zVXVAkr9OclqSByd5SlU9eJNrAAAAuD3Y9CtzJya5trX25dbazUnenuRJG14DAADA8DZd5u6b5Potl3dN1wEAALAPqrW2uW9WdUaSX2utPWO6/LtJTmytPXePr3tmkmdOF49Ncs3GFtnHYUm+LVeuXLkbyh1prXLlypW7yUy5cjeVu9N+obV27z2vPHDDi9iV5Kgtl49M8o09v6i1dm6Scze1qN6q6uLW2gly5cqVu4nckdYqV65cuZvMlCt3U7m3lU3vZvnpJMdU1dFVdVCSM5NcsOE1AAAADG+jr8y11m6pquck+XCSA5K8qbV25SbXAAAAcHuw6d0s01r7YJIPbvr7bthO7SIqV65cuZvKlCtXrtxN5460Vrly9wsbPQAKAAAAfWz6PXMAAAB0oMx1VlWnVtU1VXVtVZ3dKfNNVXVTVV3RI29L7lFV9S9VdVVVXVlVz+uUe6eq+lRVXT7lvrRH7pR9QFV9pqo+0Ctzyr2uqj5XVZdV1cUdc+9RVe+sqqun2/mXO2QeO61z9+k7VfX8DrkvmH5eV1TVeVV1p7mZU+7zpswr56xz2RxU1T2r6qKq+uL08dBOuWdM6/1RVW3riFcrcl893Rc+W1Xvqap7dMp92ZR5WVVdWFX36ZG75XMvrKpWVYd1Wu9LqurrW+7DT+i13qp67vQ7+MqqelWn9b5jy1qvq6rLOuUeV1Wf2P17p6pO7JT7i1X1b9PvtPdX1d32MXPptmHuvK3JnTVva3Jnzdua3Fnztip3y+e3NW9r1jtr3tatd868rVnvrHlbkztr3tbkzp23pY+ZOszbqtxtz9uazLmztip37qytfTy63Vnb77TWnDqdsjioy5eS3D/JQUkuT/LgDrknJTk+yRWd13tEkuOn83dN8oVO660kd5nO3yHJJ5M8otOa/yjJ25J8oPNtcV2Sw3bgPvH3SZ4xnT8oyT065x+Q5JtZ/O2ROTn3TfKVJHeeLp+f5Pc7rO8hSa5IcnAW79H9pyTHbDPrJ+YgyauSnD2dPzvJKzvlPiiLv3H50SQndFzv45McOJ1/Zcf13m3L+T9M8voeudP1R2Vx0KqvbmdGVqz3JUleOPO+tSz3V6f72B2ny4f3uh22fP61SV7cab0XJjltOv+EJB/tlPvpJI+Zzj8tycv2MXPptmHuvK3JnTVva3Jnzdua3Fnztip3urzteVuz3lnztiZ31rytux22fM0+z9ua9c6atzW5c+dt6WOmDvO2Knfb87Ymc+6srcqdO2srH4/OmbX97eSVub5OTHJta+3LrbWbk7w9yZPmhrbWPp7kP+bmLMm9obV26XT+u0muyuJB/dzc1lr77+niHabT7DdnVtWRSX49yRvmZm3C9OzcSUnemCSttZtba//Z+duckuRLrbWvdsg6MMmdq+rALMrXT/wNyG14UJJPtNa+11q7JcnHkjx5O0Er5uBJWRTmTB9/o0dua+2q1to121nnXnIvnG6HJPlEFn9rs0fud7ZcPCTbmLc1v2f+MsmfbCdzL7mzrMh9VpJXtNa+P33NTZ1ykyRVVUl+O8l5nXJbkt3P4t8925i5FbnHJvn4dP6iJL+1j5mrtg2z5m1V7tx5W5M7a97W5M6at71se7c9bzu4TV+VO2ve9rbe7c7bmtxZ87Ymd+68rXrMNHfelubOmbc1mXNnbVXu3Flb93h01rZtf6LM9XXfJNdvubwrHX6RbkJV3S/Jw7J41qJH3gHTrhE3JbmotdYj96+yGLwfdcjaU0tyYVVdUlXP7JR5/yTfSvK3tdg19A1VdUin7N3OzDYeWO6ptfb1JK9J8rUkNyT5r9bahXNzs3hV7qSquldVHZzFs6FHdcjd7Wdbazckiw1tksM7Zu+0pyX5UK+wqnp5VV2f5KlJXtwp8/QkX2+tXd4jbw/PmXafedO+7j60xgOTPLqqPllVH6uqX+qUu9ujk9zYWvtip7znJ3n19HN7TZIXdcq9Isnp0/kzMmPm9tg2dJu33tucW5E7a972zO01b1tze87bktuhy7ztkdtt3lb83GbP2x653eZtj9zZ87biMdPseduJx2K3InNbs7Yqd+6sLcvd4W3bxilzfdWS6/b7xl9Vd0nyriTP3+NZkG1rrf2wtXZcFs/OnFhVD5m5xicmuam1dkmP9S3xyNba8UlOS/LsqjqpQ+aBWez+9LrW2sOS/E8Wu0p0UVUHZbEB+YcOWYdm8Szg0Unuk+SQqvqdubmttauy2OXioiT/mMWux7es/Uc/BarqnCxuh7f2ymytndNaO2rKfM7cvKl8n5NOxXAPr0vygCTHZfHkwWs75R6Y5NAsds/54yTnT8/u9/KUdHjyZItnJXnB9HN7QaZX8Tt4Wha/xy7JYnewm7cTshPbhtsid+68LcvtMW9bc6f1dZm3JevtMm9LcrvM25r7w6x5W5LbZd6W5M6et96PmXYyd13mnFlblTt31pbkPjQ7t227TShzfe3Kjz8jc2T67Kq2Y6rqDln8Unpra+3dvfPbYrfCjyY5dWbUI5OcXlXXZbH76slV9ZaZmf+ntfaN6eNNSd6TxS6zc+1KsmvLs1bvzKLc9XJakktbazd2yHpckq+01r7VWvtBkncn+ZUOuWmtvbG1dnxr7aQsdgfr9apGktxYVUckyfRxn3er27SqOivJE5M8tbW2E0/2vC37uJvPCg/IotxfPs3dkUkuraqfmxvcWrtx2sD+KMnfpM+8JYuZe/e0a82nsngVv8sb26fdj38zyTt65E3OymLWksWTMl1uh9ba1a21x7fWHp7Fg+Ev7WvGim3D7HnbqW3Oqty583Yr1ruteVuS22Xelq23x7ytuB1mz9uan9useVuRO3veVty+s+dttz0eM3XbvnV8LLYys9e2bc1aZ23btuTufuK6+7bttqLM9fXpJMdU1dHTqyZnJrngNl7TStMzaG9MclVr7S865t67piMZVdWdsygKV8/JbK29qLV2ZGvtflncrv/cWpv9ylGSVNUhVXXX3eezeCPv7COHtta+meT6qjp2uuqUJJ+fm7tFz1cJvpbkEVV18HS/OCWL9wPMVlWHTx9/PouNc89XNi7IYgOd6eP7OmZ3V1WnJvnTJKe31r7XMfeYLRdPz8x5S5LW2udaa4e31u43zd2uLN78/8252bsfoEyenA7zNnlvkpOn7/HALA469O1O2Y9LcnVrbVenvGTxZN9jpvMnp9MTHVtm7meS/FmS1+/jv1+1bZg1bzu4zVmaO3fe1uTOmrdluT3mbc16Z83bmp/brHnby/1h2/O2JnfWvK25fefO26rHTHPnrftjsVWZHWZtVe7cWVuW+5md2rbdZtp+cBSW29Mpi/cEfSGLZ2bO6ZR5Xha7Rvwgizvd0zvlPiqL3UA/m+Sy6fSEDrkPTfKZKfeKbOPIb3vJf2w6Hs0yi/e2XT6druz1c5uyj0ty8XRbvDfJoZ1yD07y70nu3nGtL83iF+UVSd6c6QhlHXL/NYsSe3mSU2bk/MQcJLlXko9ksVH+SJJ7dsp98nT++0luTPLhTrnXZvG+2t3ztp2jTi7Lfdf0c/tskvdncZCG2bl7fP66bO9olsvW++Ykn5vWe0GSIzrlHpTkLdNtcWmSk3vdDkn+LskfdL7/PirJJdNsfDLJwzvlPi+L7dAXkrwiSe1j5tJtw9x5W5M7a97W5M6atzW5s+ZtVe7ceVuz3lnztiZ31rytux3mzNua9c6atzW5c+dt6WOmDvO2Knfb87Ymc+6srcqdO2t7fTy6nVnb3041/UcAAAAYiN0sAQAABqTMAQAADEiZAwAAGJAyBwAAMCBlDgAAYEDKHAAAwICUOQAAgAEpcwAAAAP6X0OOA/O/ok/bAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessor(text):\n    text = re.sub('<[^>]*>', ' ', str(text))\n    #text = re.sub(r'[^\\w\\s]',\" \", text)\n    text=re.sub('\\d+',' ',str(text))\n    text=re.sub('[ﾫﾻ]','',str(text))\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n                           str(text))\n    text = (re.sub('[\\W]+', ' ', text.lower().strip()) + ' ' +\n            ' '.join(emoticons).replace('-', ''))\n    return text\n\ndef strip_accents(text):\n    \"\"\"\n    Strip accents from input String.\n\n    :param text: The input string.\n    :type text: String.\n\n    :returns: The processed String.\n    :rtype: String.\n    \"\"\"\n    try:\n        text = unicode(text, 'utf-8')\n    except (TypeError, NameError): # unicode is a default on python 3 \n        pass\n    text = unicodedata.normalize('NFD', text)\n    text = text.encode('ascii', 'ignore')\n    text = text.decode(\"utf-8\")\n    return str(text)\n\nstop=set(stopwords.words(language))\n\ndef tokenizer_porter(text):\n    word_tokens = word_tokenize(text)\n    stemmer = SnowballStemmer(language, ignore_stopwords=True)\n    return [stemmer.stem(word) for word in word_tokens]\n  \n\ndef tokenizer(text):\n    stop=set(stopwords.words(language))\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w in stop]\n    filtered_sentence = [w for w in filtered_sentence if len(w)>3]\n    return filtered_sentence","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_words_documents(documents):\n    tokenized = documents = [tokenizer(strip_accents(preprocessor(document))) \n                              for document in documents]\n    all_text = []\n    for tokens in tokenized:\n        for t in tokens:\n            all_text.append(t)\n    return tokenized, set(all_text)\n\ndocuments, vocab = split_words_documents(documents)","execution_count":15,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a822ef632972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_words_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-a822ef632972>\u001b[0m in \u001b[0;36msplit_words_documents\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_words_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     tokenized = documents = [tokenizer(strip_accents(preprocessor(document))) \n\u001b[0;32m----> 3\u001b[0;31m                               for document in documents]\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-a822ef632972>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_words_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     tokenized = documents = [tokenizer(strip_accents(preprocessor(document))) \n\u001b[0;32m----> 3\u001b[0;31m                               for document in documents]\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-0615dec6516c>\u001b[0m in \u001b[0;36mtokenizer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_sentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     return [token for sent in sentences\n\u001b[0m\u001b[1;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 132\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# We are not using CONTRACTIONS4 since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.max([len(x) for x in documents]))\nprint(np.mean([len(x) for x in documents]))\nquant=np.quantile([len(x) for x in documents],.75)\nprint(quant)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocaboli=set(line.strip() for line in open('../input/prova2/prova.txt'))\nvocaboli_more=vocaboli.union(vocab)\nprint(\"Aggiunte \",len(vocaboli_more)-len(vocaboli),\"/\",len(vocab),\" parole\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dictionaries(words):\n    word_to_int_dict = {w:i+1 for i,w in enumerate(words)}\n    int_to_word_dict = {i:w for w,i in word_to_int_dict.items()}\n    return word_to_int_dict, int_to_word_dict\nword_to_int_dict, int_to_word_dict = create_dictionaries(vocaboli_more)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_text(tokenized_documents,seq_length):\n    documents = []\n    length=[]\n    for document in tokenized_documents:\n        if len(document) >= seq_length:\n            documents.append(document[:seq_length])\n            length.append(seq_length)\n        else:\n            length.append(len(document))\n            documents.append(document+['']*(seq_length-len(document)))\n    return np.array(documents),np.array(length)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_to_word_dict[0]=''\nword_to_int_dict['']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_pretrained_vectors(word2idx, fname):\n    \"\"\"Load pretrained vectors and create embedding layers.\n    \n    Args:\n        word2idx (Dict): Vocabulary built from the corpus\n        fname (str): Path to pretrained vector file\n\n    Returns:\n        embeddings (np.array): Embedding matrix with shape (N, d) where N is\n            the size of word2idx and d is embedding dimension\n    \"\"\"\n\n    print(\"Loading pretrained vectors...\")\n    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n    n, d = map(int, fin.readline().split())\n\n    # Initilize random embeddings\n    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n    embeddings[word2idx['']] = np.zeros((d,))\n\n    # Load pretrained vectors\n    count = 0\n    for line in tqdm(fin):\n        tokens = line.rstrip().split(' ')\n        word = tokens[0]\n        if word in word2idx:\n            count += 1\n            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.double)\n\n    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n\n    return embeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load pretrained vectors\nprint(\"Tokenizing...\\n\")\nembeddings = load_pretrained_vectors(word_to_int_dict, language_w)\nembeddings = torch.tensor(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#DEVICE='cpu'\nSEED = 2019\n\n#Torch\ntorch.manual_seed(SEED)\n\n#Cuda algorithms\ntorch.backends.cudnn.deterministic = True ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sort_batch(X,lengths,y):\n    lengths, indx = lengths.sort(dim=0, descending=True)\n    X = X[indx]\n    y = y[indx]\n    return X,lengths, y ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data_loader(train_c,train_len, valid_c, valid_len, train_l,valid_l,batch_size):\n    x_train = torch.tensor(train_c, dtype=torch.long,device=DEVICE)\n    x_train_len = torch.tensor(train_len, dtype=torch.long,device=DEVICE)\n    y_train = torch.tensor(train_l, dtype=torch.long, device=DEVICE)\n    x_cv = torch.tensor(valid_c, dtype=torch.long, device=DEVICE)\n    x_cv_len = torch.tensor(valid_len, dtype=torch.long, device=DEVICE)\n    y_cv = torch.tensor(valid_l, dtype=torch.long, device=DEVICE)\n    # Create Torch datasets\n    train = torch.utils.data.TensorDataset(x_train,x_train_len, y_train)\n    valid = torch.utils.data.TensorDataset(x_cv,x_cv_len, y_cv)\n    # Create Data Loaders\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n    return train_loader, valid_loader\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_graph(train_loss, valid_loss):\n    fig = plt.figure(figsize=(10,8))\n    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n\n    # find position of lowest validation loss\n    minposs = valid_loss.index(min(valid_loss))+1 \n    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    #plt.ylim(0, 0.5) # consistent scale\n    #plt.xlim(0, len(train_loss)+1) # consistent scale\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\n#https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print            \n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationCNN(nn.Module):\n    \n    def __init__(self, \n                 pretrained_embedding=None,\n                 freeze_embedding=False,\n                 n_vocab=None, \n                 n_embed=300,\n                 n_filters=100, \n                 n_output=1, \n                 filter_sizes=[2,3,4], \n                 dropout = 0.8,\n                 pad_idx=0.0):\n        super().__init__()\n        # Embedding layer\n        if pretrained_embedding is not None:\n            self.n_vocab, self.n_embed = pretrained_embedding.shape\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n                                                          freeze=freeze_embedding)\n        \n        \n         \n        self.dropout = nn.Dropout(dropout)\n        self.convs = nn.ModuleList([\n                                    nn.Conv1d(in_channels = self.n_embed, \n                                              out_channels = n_filters, \n                                              kernel_size = fs) \n                                    for fs in filter_sizes\n                                    ])\n        \n        \n        self.fc1 = nn.Linear(len(filter_sizes) * n_filters, n_filters)\n        self.fc2 = nn.Linear(n_filters, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.relu = nn.ReLU()\n        \n\n        \n        \n    def forward(self, text,len_text):\n        \n        emb = self.embedding(text)\n        emb=emb.transpose(2,1)\n        conved = [F.relu(c(emb)) for c in self.convs] \n        #al max_pool1d diamo come parametro il filter size\n        pooled = [F.max_pool1d(c, c.shape[2]).squeeze(2) for c in conved]\n        concat = self.dropout(torch.cat(pooled, dim = 1))\n        out=self.fc1(concat)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, data_loader, criterion):\n    model.eval()\n    val_accuracy = []\n    val_loss = []\n    with torch.no_grad():\n        for i, (x_batch,len_batch, y_batch) in enumerate(data_loader):\n            #x_batch,len_batch, y_batch=sort_batch(x_batch,len_batch, y_batch)\n            logits= model(x_batch,len_batch)\n            loss = criterion(logits, y_batch)\n            val_loss.append(loss.item())\n            \n            _, preds = torch.max(logits, 1)\n            accuracy = (preds == y_batch).cpu().numpy().mean() * 100\n            val_accuracy.append(accuracy)\n        val_accuracy = np.mean(val_accuracy)\n        return val_loss, val_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, optimizer,criterion, train_loader, val_loader=None, patience=7, epochs=10):\n    print(\"Start training...\\n\")\n    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n    print(\"-\"*60)\n    best_accuracy=0\n    # to track the training loss as the model trains\n    train_losses = []\n    # to track the validation loss as the model trains\n    valid_losses = []\n    # to track the average training loss per epoch as the model trains\n    avg_train_losses = []\n    # to track the average validation loss per epoch as the model trains\n    avg_valid_losses = []\n    \n    # initialize the early_stopping object\n    early_stopping = EarlyStopping(patience=patience, verbose=True)\n    \n    for epoch in range(1, epochs + 1):\n        start_time = time.time()\n        t0_epoch = time.time()\n        total_loss = 0\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for i, (x_batch,len_batch, y_batch) in enumerate(train_loader):\n            #x_batch,len_batch, y_batch=sort_batch(x_batch,len_batch, y_batch)\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            y_pred= model(x_batch,len_batch)\n            # calculate the loss\n            loss = criterion(y_pred, y_batch)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # record training loss\n            train_losses.append(loss.item())\n            \n        ######################    \n        # validate the model #\n        ###################### \n        valid_losses, val_accuracy = evaluate(model, val_loader,criterion)\n        \n        # calculate average loss over an epoch\n        train_loss = np.average(train_losses)\n        valid_loss = np.average(valid_losses)\n        avg_train_losses.append(train_loss)\n        avg_valid_losses.append(valid_loss)\n        \n        time_elapsed = time.time() - t0_epoch\n        print(f\"{epoch :^7} | {train_loss:^12.6f} | {valid_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n        \n        # clear lists to track next epoch\n        train_losses = []\n        valid_losses = []\n        \n        # early_stopping needs the validation loss to check if it has decresed, \n        # and if it has, it will make a checkpoint of the current model\n        early_stopping(valid_loss, model)\n        \n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n        \n        \n    print(\"\\n\")\n    \n    plot_graph(avg_train_losses, avg_valid_losses)\n    model.load_state_dict(torch.load('checkpoint.pt'))\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pytorch_predict(model, test_loader):\n    '''\n    Make prediction from a pytorch model \n    '''\n    # set model to evaluate model\n    model.eval()\n    labels=[]\n    with torch.no_grad():\n        for (text,length, label) in test_loader: \n            #text,length, label=sort_batch(text,length, label)\n            outputs = model(text,length)\n            _, preds = torch.max(outputs, 1)\n            for pred in preds:\n                labels.append(pred.item())\n    \n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\noutput_dim = len(np.unique(classes))\nnumber_of_filters = 100\nfilter_sizes = [1,2,3]\ndropout_pc = 0.5\nn_epochs = 100\nnfold=10\npatience=5\nlr = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\n\ny=np.array(classes)\ndocuments=np.array(documents)\nkfold = StratifiedKFold(n_splits=nfold).split(documents, y)\n\naccuracys = []\nscores= []\nmetriche = np.zeros((nfold,4,output_dim))\n\n#target_names=le.inverse_transform(target_names)\n\nfor k, (train_ids, test_ids) in enumerate(kfold):\n    \n    padded_sentences_train,lenght_train = pad_text(documents[train_ids], seq_length = int(quant))\n    padded_sentences_test,lenght_test = pad_text(documents[test_ids], seq_length = int(quant))\n    \n    encoded_sentences_train = np.array([[word_to_int_dict[word] if word in word_to_int_dict else 0 for word in content ] for content in padded_sentences_train])\n    encoded_sentences_test  = np.array([[word_to_int_dict[word] if word in word_to_int_dict else 0 for word in content ] for content in padded_sentences_test])\n    \n    print(\"train:\",encoded_sentences_train.shape,\"len:\",lenght_train.size, \"train_y:\",y[train_ids].size)\n    print(\"test:\",encoded_sentences_test.shape,\"len:\",lenght_test.size)\n    \n    \n    \n    train_loader, val_loader=create_data_loader(encoded_sentences_train,lenght_train,\n                                                encoded_sentences_test,lenght_test,\n                                                y[train_ids],y[test_ids],batch_size)\n    \n    \n    model = ClassificationCNN(\n                        pretrained_embedding=embeddings, \n                        n_output=output_dim,\n                        filter_sizes=filter_sizes,\n                        dropout=dropout_pc,\n                        n_filters=number_of_filters)\n    model=model.double()\n    loss_fn = nn.CrossEntropyLoss(reduction='sum').to(DEVICE)\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=lr,weight_decay=0.01)\n    model.to(DEVICE)\n    model=train(model,optimizer,loss_fn,train_loader,val_loader,patience,n_epochs)\n    \n    \n    y_pred=pytorch_predict(model,val_loader)\n    \n    y_true=y[test_ids]\n    \n    target_names=np.unique(y[train_ids])\n    accuracys.append(metrics.accuracy_score(y_true, y_pred))\n    score=precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=target_names, average=\"weighted\")\n    scores.append(score[0:3])\n    print('--------------- Fold: %2d ---------------------'% (k+1))\n    print()\n    target_names = list(map(str,target_names))\n    print(metrics.classification_report(y_true, y_pred, target_names=target_names))\n    dizionario=metrics.classification_report(y_true, y_pred, target_names=target_names,output_dict=True)\n    for k_d,(m_id, m_info) in enumerate(dizionario.items()):\n        if k_d<output_dim:\n            for j_d,key in enumerate(m_info):\n                metriche[k,j_d,k_d]=m_info[key]\n        else:\n            break\n    \n    conf_mat = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(10,10))\n    sns.heatmap(conf_mat, annot=True, fmt='d',\n                xticklabels=target_names , yticklabels=target_names )\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.show()\n    print()\n\narr = np.array(scores)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Overall results of the cross-validation procedure\")\nprint()\nprint(f\"{'Class':^7} | {'precision':^9}{'':^6} | {'recall':^10}{'':^5} | {'f1-measure':^6}{'':^5} | {'support':^9}\")\nfor i in range(output_dim):\n    print(f\"{i :^7} | {np.mean(metriche[:,0,i])*100:^5.2f} +/-{np.std(metriche[:,0,i])*100:^6.2f} | {np.mean(metriche[:,1,i])*100:^5.2f} +/-{np.std(metriche[:,1,i])*100:^6.2f} | {np.mean(metriche[:,2,i])*100:^5.2f} +/-{np.std(metriche[:,2,i])*100:^6.2f} | {np.mean(metriche[:,3,i]):^9.2f}\")\nprint()\nprint('\\nCV accuracy: %.2f +/- %.2f max: %.2f' % (np.mean(accuracys)*100, np.std(accuracys)*100,np.max(accuracys)*100))\nprint('\\nCV precision: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,0])*100, np.std(arr[:,0])*100,np.max(arr[:,0])*100))\nprint('\\nCV recall: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,1])*100, np.std(arr[:,1])*100,np.max(arr[:,1])*100))\nprint('\\nCV f1: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,2])*100, np.std(arr[:,2])*100,np.max(arr[:,2])*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}