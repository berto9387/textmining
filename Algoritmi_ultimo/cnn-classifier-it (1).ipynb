{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import librerie"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import word_tokenize \nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport seaborn as sns\nfrom lime import lime_text\nimport unicodedata\nimport pandas as pd\nfrom string import punctuation\nimport numpy as np\nimport torch\nfrom nltk.tokenize import word_tokenize\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch import nn\nfrom torch import optim\nfrom tqdm import tqdm\nfrom sklearn import preprocessing\nimport time\nimport random\nimport torch.nn.functional as F","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"language=\"italian\"\nlanguage_w=\"../input/fasttext-aligned-word-vectors/wiki.it.align.vec\"\n","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text=\"question_description\"\n#review=\"ministry\"\n#n_top_class=35\n#path_db=\"/kaggle/input/rajyasabha/rajyasabha_q*.{}\"\n#import glob\n#import pandas as pd\n#extension = 'csv'\n#all_filenames = [i for i in glob.glob(path_db.format(extension))]\n#combine all files in the list\n#df = pd.concat([pd.read_csv(f,encoding='latin1') for f in all_filenames ])\n\n","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text=\"testo\"\nreview=\"cap_maj_master\"\npath_db=\"../input/ciao9cci/politica.xlsx\"\nn_top_class=35\ndf = pd.read_excel(path_db, sheet_name=\"Foglio1\")","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_class=df.groupby(review).count()[[text]]\ntop_class=top_class.sort_values(by=[text], ascending=False).head(n_top_class)\ntop_class=top_class.apply(list).reset_index()\ntop_class = [d for d in top_class[review]]\nprint(top_class)\n\ndf=df.loc[df[review].isin(top_class)]\nprint(f'Found {len(df)} texts.')\nprint(f'{df[review].isnull().sum()} document(s) with no classification removed')\ndf=df[pd.notnull(df[review])]\n\ndf = df[df[text].str.split().str.len().gt(5)]\n\nprint(f'{df[text].isnull().sum()} document(s) with no text removed')\ndf=df[pd.notnull(df[text])]\n\nle = preprocessing.LabelEncoder()\nle.fit(df[review])\ndf[review]=le.transform(df[review])\nclasses = [int(c) for c in df[review].values]\ndocuments = [d for d in df[text]]","execution_count":47,"outputs":[{"output_type":"stream","text":"[12.0, 10.0, 20.0, 1.0, 3.0, 15.0, 5.0, 6.0, 7.0, 19.0, 4.0, 9.0, 2.0, 16.0, 21.0, 8.0, 13.0, 17.0, 14.0, 23.0, 18.0]\nFound 5672 texts.\n0 document(s) with no classification removed\n0 document(s) with no text removed\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Import dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.bincount(classes)\nx = np.arange(len(y))\nprint(len(y))\nfig, ax = plt.subplots(figsize=(15,22))\nplt.bar(x, y,width=0.7)\nax.set_xticks(x)\nax.set_aspect('auto')\nplt.show()\n","execution_count":48,"outputs":[{"output_type":"stream","text":"21\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x1584 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessor(text):\n    text = re.sub('<[^>]*>', ' ', str(text))\n    #text = re.sub(r'[^\\w\\s]',\" \", text)\n    text=re.sub('\\d+',' ',str(text))\n    text=re.sub('[ﾫﾻ]','',str(text))\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n                           str(text))\n    text = (re.sub('[\\W]+', ' ', text.lower().strip()) + ' ' +\n            ' '.join(emoticons).replace('-', ''))\n    return text\n\ndef strip_accents(text):\n    \"\"\"\n    Strip accents from input String.\n\n    :param text: The input string.\n    :type text: String.\n\n    :returns: The processed String.\n    :rtype: String.\n    \"\"\"\n    try:\n        text = unicode(text, 'utf-8')\n    except (TypeError, NameError): # unicode is a default on python 3 \n        pass\n    text = unicodedata.normalize('NFD', text)\n    text = text.encode('ascii', 'ignore')\n    text = text.decode(\"utf-8\")\n    return str(text)\n\nstop=set(stopwords.words(language))\n\ndef tokenizer_porter(text):\n    word_tokens = word_tokenize(text)\n    stemmer = SnowballStemmer(language, ignore_stopwords=True)\n    return [stemmer.stem(word) for word in word_tokens]\n  \n\ndef tokenizer(text):\n    stop=set(stopwords.words(language))\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w in stop]\n    filtered_sentence = [w for w in filtered_sentence if len(w)>3]\n    return filtered_sentence","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_words_documents(documents):\n    tokenized = documents = [tokenizer(strip_accents(preprocessor(document))) \n                              for document in documents]\n    all_text = []\n    for tokens in tokenized:\n        for t in tokens:\n            all_text.append(t)\n    return tokenized, set(all_text)\n\ndocuments, vocab = split_words_documents(documents)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.max([len(x) for x in documents]))\nprint(np.mean([len(x) for x in documents]))\nquant=np.quantile([len(x) for x in documents],.75)\nprint(quant)","execution_count":51,"outputs":[{"output_type":"stream","text":"1375\n201.02611015818562\n248.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocaboli=set(line.strip() for line in open('../input/prova2/prova.txt'))\nvocaboli_more=vocaboli.union(vocab)\nprint(\"Aggiunte \",len(vocaboli_more)-len(vocaboli),\"/\",len(vocab),\" parole\")","execution_count":52,"outputs":[{"output_type":"stream","text":"Aggiunte  14648 / 49263  parole\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dictionaries(words):\n    word_to_int_dict = {w:i+1 for i,w in enumerate(words)}\n    int_to_word_dict = {i:w for w,i in word_to_int_dict.items()}\n    return word_to_int_dict, int_to_word_dict\nword_to_int_dict, int_to_word_dict = create_dictionaries(vocaboli)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pad_text(tokenized_documents,seq_length):\n    documents = []\n    length=[]\n    for document in tokenized_documents:\n        if len(document) >= seq_length:\n            documents.append(document[:seq_length])\n            length.append(seq_length)\n        else:\n            length.append(len(document))\n            documents.append(document+['']*(seq_length-len(document)))\n    return np.array(documents),np.array(length)\n","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_to_word_dict[0]=''\nword_to_int_dict['']=0","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_pretrained_vectors(word2idx, fname):\n    \"\"\"Load pretrained vectors and create embedding layers.\n    \n    Args:\n        word2idx (Dict): Vocabulary built from the corpus\n        fname (str): Path to pretrained vector file\n\n    Returns:\n        embeddings (np.array): Embedding matrix with shape (N, d) where N is\n            the size of word2idx and d is embedding dimension\n    \"\"\"\n\n    print(\"Loading pretrained vectors...\")\n    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n    n, d = map(int, fin.readline().split())\n\n    # Initilize random embeddings\n    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n    embeddings[word2idx['']] = np.zeros((d,))\n\n    # Load pretrained vectors\n    count = 0\n    for line in tqdm(fin):\n        tokens = line.rstrip().split(' ')\n        word = tokens[0]\n        if word in word2idx:\n            count += 1\n            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.double)\n\n    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n\n    return embeddings","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load pretrained vectors\nprint(\"Tokenizing...\\n\")\nembeddings = load_pretrained_vectors(word_to_int_dict, language_w)\nembeddings = torch.tensor(embeddings)","execution_count":57,"outputs":[{"output_type":"stream","text":"Tokenizing...\n\nLoading pretrained vectors...\n","name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/fasttext-aligned-word-vectors/wiki.in.align.vec'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-8516b373d308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load pretrained vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenizing...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_int_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-56-860389a448d3>\u001b[0m in \u001b[0;36mload_pretrained_vectors\u001b[0;34m(word2idx, fname)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading pretrained vectors...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/fasttext-aligned-word-vectors/wiki.in.align.vec'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#DEVICE='cpu'\nSEED = 2019\n\n#Torch\ntorch.manual_seed(SEED)\n\n#Cuda algorithms\ntorch.backends.cudnn.deterministic = True ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sort_batch(X,lengths,y):\n    lengths, indx = lengths.sort(dim=0, descending=True)\n    X = X[indx]\n    y = y[indx]\n    return X,lengths, y ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data_loader(train_c,train_len, valid_c, valid_len, train_l,valid_l,batch_size):\n    x_train = torch.tensor(train_c, dtype=torch.long,device=DEVICE)\n    x_train_len = torch.tensor(train_len, dtype=torch.long,device=DEVICE)\n    y_train = torch.tensor(train_l, dtype=torch.long, device=DEVICE)\n    x_cv = torch.tensor(valid_c, dtype=torch.long, device=DEVICE)\n    x_cv_len = torch.tensor(valid_len, dtype=torch.long, device=DEVICE)\n    y_cv = torch.tensor(valid_l, dtype=torch.long, device=DEVICE)\n    # Create Torch datasets\n    train = torch.utils.data.TensorDataset(x_train,x_train_len, y_train)\n    valid = torch.utils.data.TensorDataset(x_cv,x_cv_len, y_cv)\n    # Create Data Loaders\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n    return train_loader, valid_loader\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_graph(train_loss, valid_loss):\n    fig = plt.figure(figsize=(10,8))\n    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n\n    # find position of lowest validation loss\n    minposs = valid_loss.index(min(valid_loss))+1 \n    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    #plt.ylim(0, 0.5) # consistent scale\n    #plt.xlim(0, len(train_loss)+1) # consistent scale\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\n#https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print            \n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationCNN(nn.Module):\n    \n    def __init__(self, \n                 pretrained_embedding=None,\n                 freeze_embedding=False,\n                 n_vocab=None, \n                 n_embed=300,\n                 n_filters=100, \n                 n_output=1, \n                 filter_sizes=[2,3,4], \n                 dropout = 0.8,\n                 pad_idx=0.0):\n        super().__init__()\n        # Embedding layer\n        if pretrained_embedding is not None:\n            self.n_vocab, self.n_embed = pretrained_embedding.shape\n            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n                                                          freeze=freeze_embedding)\n        \n        \n         \n        self.dropout = nn.Dropout(dropout)\n        self.convs = nn.ModuleList([\n                                    nn.Conv1d(in_channels = self.n_embed, \n                                              out_channels = n_filters, \n                                              kernel_size = fs) \n                                    for fs in filter_sizes\n                                    ])\n        \n        \n        self.fc1 = nn.Linear(len(filter_sizes) * n_filters, n_filters)\n        self.fc2 = nn.Linear(n_filters, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.relu = nn.ReLU()\n        \n\n        \n        \n    def forward(self, text,len_text):\n        \n        emb = self.embedding(text)\n        emb=emb.transpose(2,1)\n        conved = [F.relu(c(emb)) for c in self.convs] \n        #al max_pool1d diamo come parametro il filter size\n        pooled = [F.max_pool1d(c, c.shape[2]).squeeze(2) for c in conved]\n        concat = self.dropout(torch.cat(pooled, dim = 1))\n        out=self.fc1(concat)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, data_loader, criterion):\n    model.eval()\n    val_accuracy = []\n    val_loss = []\n    with torch.no_grad():\n        for i, (x_batch,len_batch, y_batch) in enumerate(data_loader):\n            #x_batch,len_batch, y_batch=sort_batch(x_batch,len_batch, y_batch)\n            logits= model(x_batch,len_batch)\n            loss = criterion(logits, y_batch)\n            val_loss.append(loss.item())\n            \n            _, preds = torch.max(logits, 1)\n            accuracy = (preds == y_batch).cpu().numpy().mean() * 100\n            val_accuracy.append(accuracy)\n        val_accuracy = np.mean(val_accuracy)\n        return val_loss, val_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, optimizer,criterion, train_loader, val_loader=None, patience=7, epochs=10):\n    print(\"Start training...\\n\")\n    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n    print(\"-\"*60)\n    best_accuracy=0\n    # to track the training loss as the model trains\n    train_losses = []\n    # to track the validation loss as the model trains\n    valid_losses = []\n    # to track the average training loss per epoch as the model trains\n    avg_train_losses = []\n    # to track the average validation loss per epoch as the model trains\n    avg_valid_losses = []\n    \n    # initialize the early_stopping object\n    early_stopping = EarlyStopping(patience=patience, verbose=True)\n    \n    for epoch in range(1, epochs + 1):\n        start_time = time.time()\n        t0_epoch = time.time()\n        total_loss = 0\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for i, (x_batch,len_batch, y_batch) in enumerate(train_loader):\n            #x_batch,len_batch, y_batch=sort_batch(x_batch,len_batch, y_batch)\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            y_pred= model(x_batch,len_batch)\n            # calculate the loss\n            loss = criterion(y_pred, y_batch)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # record training loss\n            train_losses.append(loss.item())\n            \n        ######################    \n        # validate the model #\n        ###################### \n        valid_losses, val_accuracy = evaluate(model, val_loader,criterion)\n        \n        # calculate average loss over an epoch\n        train_loss = np.average(train_losses)\n        valid_loss = np.average(valid_losses)\n        avg_train_losses.append(train_loss)\n        avg_valid_losses.append(valid_loss)\n        \n        time_elapsed = time.time() - t0_epoch\n        print(f\"{epoch :^7} | {train_loss:^12.6f} | {valid_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n        \n        # clear lists to track next epoch\n        train_losses = []\n        valid_losses = []\n        \n        # early_stopping needs the validation loss to check if it has decresed, \n        # and if it has, it will make a checkpoint of the current model\n        early_stopping(valid_loss, model)\n        \n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n        \n        \n    print(\"\\n\")\n    \n    plot_graph(avg_train_losses, avg_valid_losses)\n    model.load_state_dict(torch.load('checkpoint.pt'))\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pytorch_predict(model, test_loader):\n    '''\n    Make prediction from a pytorch model \n    '''\n    # set model to evaluate model\n    model.eval()\n    labels=[]\n    with torch.no_grad():\n        for (text,length, label) in test_loader: \n            #text,length, label=sort_batch(text,length, label)\n            outputs = model(text,length)\n            _, preds = torch.max(outputs, 1)\n            for pred in preds:\n                labels.append(pred.item())\n    \n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\noutput_dim = len(np.unique(classes))\nnumber_of_filters = 100\nfilter_sizes = [1,2,3]\ndropout_pc = 0.5\nn_epochs = 100\nnfold=10\npatience=5\nlr = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\n\ny=np.array(classes)\ndocuments=np.array(documents)\nkfold = StratifiedKFold(n_splits=nfold).split(documents, y)\n\naccuracys = []\nscores= []\nmetriche = np.zeros((nfold,4,output_dim))\n\n#target_names=le.inverse_transform(target_names)\n\nfor k, (train_ids, test_ids) in enumerate(kfold):\n    \n    padded_sentences_train,lenght_train = pad_text(documents[train_ids], seq_length = int(quant))\n    padded_sentences_test,lenght_test = pad_text(documents[test_ids], seq_length = int(quant))\n    \n    encoded_sentences_train = np.array([[word_to_int_dict[word] if word in word_to_int_dict else 0 for word in content ] for content in padded_sentences_train])\n    encoded_sentences_test  = np.array([[word_to_int_dict[word] if word in word_to_int_dict else 0 for word in content ] for content in padded_sentences_test])\n    \n    print(\"train:\",encoded_sentences_train.shape,\"len:\",lenght_train.size, \"train_y:\",y[train_ids].size)\n    print(\"test:\",encoded_sentences_test.shape,\"len:\",lenght_test.size)\n    \n    \n    \n    train_loader, val_loader=create_data_loader(encoded_sentences_train,lenght_train,\n                                                encoded_sentences_test,lenght_test,\n                                                y[train_ids],y[test_ids],batch_size)\n    \n    \n    model = ClassificationCNN(\n                        pretrained_embedding=embeddings, \n                        n_output=output_dim,\n                        filter_sizes=filter_sizes,\n                        dropout=dropout_pc,\n                        n_filters=number_of_filters)\n    model=model.double()\n    loss_fn = nn.CrossEntropyLoss(reduction='sum').to(DEVICE)\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=lr,weight_decay=0.01)\n    model.to(DEVICE)\n    model=train(model,optimizer,loss_fn,train_loader,val_loader,patience,n_epochs)\n    \n    \n    y_pred=pytorch_predict(model,val_loader)\n    \n    y_true=y[test_ids]\n    \n    target_names=np.unique(y[train_ids])\n    accuracys.append(metrics.accuracy_score(y_true, y_pred))\n    score=precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=target_names, average=\"weighted\")\n    scores.append(score[0:3])\n    print('--------------- Fold: %2d ---------------------'% (k+1))\n    print()\n    target_names = list(map(str,target_names))\n    print(metrics.classification_report(y_true, y_pred, target_names=target_names))\n    dizionario=metrics.classification_report(y_true, y_pred, target_names=target_names,output_dict=True)\n    for k_d,(m_id, m_info) in enumerate(dizionario.items()):\n        if k_d<output_dim:\n            for j_d,key in enumerate(m_info):\n                metriche[k,j_d,k_d]=m_info[key]\n        else:\n            break\n    \n    conf_mat = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots(figsize=(10,10))\n    sns.heatmap(conf_mat, annot=True, fmt='d',\n                xticklabels=target_names , yticklabels=target_names )\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.show()\n    print()\n\narr = np.array(scores)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Overall results of the cross-validation procedure\")\nprint()\nprint(f\"{'Class':^7} | {'precision':^9}{'':^6} | {'recall':^10}{'':^5} | {'f1-measure':^6}{'':^5} | {'support':^9}\")\nfor i in range(output_dim):\n    print(f\"{i :^7} | {np.mean(metriche[:,0,i])*100:^5.2f} +/-{np.std(metriche[:,0,i])*100:^6.2f} | {np.mean(metriche[:,1,i])*100:^5.2f} +/-{np.std(metriche[:,1,i])*100:^6.2f} | {np.mean(metriche[:,2,i])*100:^5.2f} +/-{np.std(metriche[:,2,i])*100:^6.2f} | {np.mean(metriche[:,3,i]):^9.2f}\")\nprint()\nprint('\\nCV accuracy: %.2f +/- %.2f max: %.2f' % (np.mean(accuracys)*100, np.std(accuracys)*100,np.max(accuracys)*100))\nprint('\\nCV precision: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,0])*100, np.std(arr[:,0])*100,np.max(arr[:,0])*100))\nprint('\\nCV recall: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,1])*100, np.std(arr[:,1])*100,np.max(arr[:,1])*100))\nprint('\\nCV f1: %.2f +/- %.2f max: %.2f' % (np.mean(arr[:,2])*100, np.std(arr[:,2])*100,np.max(arr[:,2])*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}