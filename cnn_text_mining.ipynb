{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\berto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"all\")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5674 texts.\n",
      "2 document(s) with no classification removed\n",
      "424 document(s) with no text removed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>: quali siano le determinazioni del Governo in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>: quali siano le valutazioni del Governo sugli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>- premesso che: la prospettata modifica degli ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  : quali siano le determinazioni del Governo in...\n",
       "1          1  : quali siano le valutazioni del Governo sugli...\n",
       "2          1  - premesso che: la prospettata modifica degli ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('./politica.xlsx', sheet_name=\"Foglio1\")\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "print(f'Found {len(df)} texts.')\n",
    "\n",
    "print(f'{df[\"cap_maj_master\"].isnull().sum()} document(s) with no classification removed')\n",
    "df=df[pd.notnull(df['cap_maj_master'])]\n",
    "\n",
    "print(f'{df[\"testo\"].isnull().sum()} document(s) with no text removed')\n",
    "df=df[pd.notnull(df['testo'])]\n",
    "\n",
    "classes = [int(c) for c in df['cap_maj_master']]\n",
    "documents = [d for d in df['testo']]\n",
    "df = df[['cap_maj_master', 'testo']]\n",
    "df.columns = ['sentiment', 'review']\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', ' ', str(text))\n",
    "    text=re.sub('\\d+',' ',str(text))\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           str(text))\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "import unicodedata\n",
    "\n",
    "def strip_accents(text):\n",
    "\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode(\"utf-8\")\n",
    "\n",
    "    return text\n",
    "def tokenizer_porter(text):\n",
    "    stop=stopwords.words('italian')\n",
    "    stemmer = SnowballStemmer(\"italian\", ignore_stopwords=True)\n",
    "    return [stemmer.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[qual, siano, le, determin, del, govern, in, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[qual, siano, le, valut, del, govern, sugli, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[premess, che, la, prospett, modif, degli, sca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  [qual, siano, le, determin, del, govern, in, m...\n",
       "1          1  [qual, siano, le, valut, del, govern, sugli, e...\n",
       "2          1  [premess, che, la, prospett, modif, degli, sca..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(preprocessor).apply(strip_accents).apply(tokenizer_porter)\n",
    "df['sentiment']=df['sentiment'].astype(int)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5248,)\n",
      "(5248,)\n"
     ]
    }
   ],
   "source": [
    "X, y = df.iloc[:,1].values, df.iloc[:,0].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "def tokenize(texts):\n",
    "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): List of text data\n",
    "    \n",
    "    Returns:\n",
    "        tokenized_texts (List[List[str]]): List of list of tokens\n",
    "        word2idx (Dict): Vocabulary built from the corpus\n",
    "        max_len (int): Maximum sentence length\n",
    "    \"\"\"\n",
    "\n",
    "    max_len = 0\n",
    "    tokenized_texts = []\n",
    "    word2idx = {}\n",
    "\n",
    "    # Add <pad> and <unk> tokens to the vocabulary\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "\n",
    "    # Building our vocab from the corpus starting from index 2\n",
    "    idx = 2\n",
    "    for sent in texts:\n",
    "        \n",
    "\n",
    "        # Add `tokenized_sent` to `tokenized_texts`\n",
    "        tokenized_texts.append(sent)\n",
    "\n",
    "        # Add new token to `word2idx`\n",
    "        for token in sent:\n",
    "            if token not in word2idx:\n",
    "                word2idx[token] = idx\n",
    "                idx += 1\n",
    "\n",
    "        # Update `max_len`\n",
    "        max_len = max(max_len, len(sent))\n",
    "\n",
    "    return tokenized_texts, word2idx, max_len\n",
    "\n",
    "def encode(tokenized_texts, word2idx, max_len):\n",
    "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
    "    their index in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
    "            shape (N, max_len). It will the input of our CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = []\n",
    "    for tokenized_sent in tokenized_texts:\n",
    "        # Pad sentences to max_len\n",
    "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
    "\n",
    "        # Encode tokens to input_ids\n",
    "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
    "        input_ids.append(input_id)\n",
    "    \n",
    "    return np.array(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def load_pretrained_vectors(word2idx, fname):\n",
    "    \"\"\"Load pretrained vectors and create embedding layers.\n",
    "    \n",
    "    Args:\n",
    "        word2idx (Dict): Vocabulary built from the corpus\n",
    "        fname (str): Path to pretrained vector file\n",
    "\n",
    "    Returns:\n",
    "        embeddings (np.array): Embedding matrix with shape (N, d) where N is\n",
    "            the size of word2idx and d is embedding dimension\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading pretrained vectors...\")\n",
    "    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "\n",
    "    # Initilize random embeddings\n",
    "    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n",
    "    embeddings[word2idx['<pad>']] = np.zeros((d,))\n",
    "\n",
    "    # Load pretrained vectors\n",
    "    count = 0\n",
    "    for line in tqdm_notebook(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        word = tokens[0]\n",
    "        if word in word2idx:\n",
    "            count += 1\n",
    "            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.float32)\n",
    "\n",
    "    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenized_texts, word2idx, max_len = tokenize(X)\n",
    "input_ids = encode(tokenized_texts, word2idx, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "\n",
      "Loading pretrained vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b47afdb8d107>:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(fin):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ee3d7bbee748a19d7a4bcb9bf08147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 9384 / 25951 pretrained vectors found.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained vectors\n",
    "print(\"Tokenizing...\\n\")\n",
    "embeddings = load_pretrained_vectors(word2idx, \"cc.it.300.vec\")\n",
    "embeddings = torch.tensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0320,  0.1485, -0.0827,  ...,  0.2329, -0.0979,  0.1566],\n",
      "        [ 0.0652,  0.0253,  0.0615,  ..., -0.0311, -0.0450, -0.0271],\n",
      "        ...,\n",
      "        [-0.2294, -0.0269, -0.0631,  ...,  0.1661, -0.2073,  0.0126],\n",
      "        [ 0.1137,  0.0190, -0.0317,  ...,  0.0396, -0.0247,  0.0026],\n",
      "        [ 0.2227, -0.0111, -0.2257,  ..., -0.0008, -0.1436,  0.1566]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   3   4 ...   0   0   0]\n",
      " [  2   3   4 ...   0   0   0]\n",
      " [ 59  60  61 ...   0   0   0]\n",
      " ...\n",
      " [ 59  60  71 ...   0   0   0]\n",
      " [ 59  60   8 ...   0   0   0]\n",
      " [ 59  60 790 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
    "                              SequentialSampler)\n",
    "\n",
    "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
    "                batch_size=50):\n",
    "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
    "    DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert data type to torch.Tensor\n",
    "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
    "    tuple(torch.tensor(data) for data in\n",
    "          [train_inputs, val_inputs, train_labels, val_labels])\n",
    "\n",
    "    # Specify batch_size\n",
    "    batch_size = 50\n",
    "\n",
    "    # Create DataLoader for training data\n",
    "    train_data = TensorDataset(train_inputs, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Create DataLoader for validation data\n",
    "    val_data = TensorDataset(val_inputs, val_labels)\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample configuration:\n",
    "filter_sizes = [2, 3, 4]\n",
    "num_filters = [2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_NLP(nn.Module):\n",
    "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
    "    def __init__(self,\n",
    "                 pretrained_embedding=None,\n",
    "                 freeze_embedding=False,\n",
    "                 vocab_size=None,\n",
    "                 embed_dim=300,\n",
    "                 filter_sizes=[3, 4, 5],\n",
    "                 num_filters=[100, 100, 100],\n",
    "                 num_classes=2,\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        The constructor for CNN_NLP class.\n",
    "\n",
    "        Args:\n",
    "            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n",
    "                shape (vocab_size, embed_dim)\n",
    "            freeze_embedding (bool): Set to False to fine-tune pretraiend\n",
    "                vectors. Default: False\n",
    "            vocab_size (int): Need to be specified when not pretrained word\n",
    "                embeddings are not used.\n",
    "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
    "                when pretrained word embeddings are not used. Default: 300\n",
    "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
    "            num_filters (List[int]): List of number of filters, has the same\n",
    "                length as `filter_sizes`. Default: [100, 100, 100]\n",
    "            n_classes (int): Number of classes. Default: 2\n",
    "            dropout (float): Dropout rate. Default: 0.5\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNN_NLP, self).__init__()\n",
    "        # Embedding layer\n",
    "        if pretrained_embedding is not None:\n",
    "            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
    "                                                          freeze=freeze_embedding)\n",
    "        else:\n",
    "            self.embed_dim = embed_dim\n",
    "            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                          embedding_dim=self.embed_dim,\n",
    "                                          padding_idx=0,\n",
    "                                          max_norm=5.0)\n",
    "        # Conv Network\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.embed_dim,\n",
    "                      out_channels=num_filters[i],\n",
    "                      kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))\n",
    "        ])\n",
    "        # Fully-connected layer and Dropout\n",
    "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"Perform a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): A tensor of token ids with shape\n",
    "                (batch_size, max_sent_length)\n",
    "\n",
    "        Returns:\n",
    "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
    "                n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
    "        \n",
    "        x_embed = self.embedding(input_ids.long()).float()\n",
    "\n",
    "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
    "        # Output shape: (b, embed_dim, max_len)\n",
    "        x_reshaped = x_embed.permute(0, 2, 1)\n",
    "\n",
    "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "\n",
    "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in x_conv_list]\n",
    "        \n",
    "        # Concatenate x_pool_list to feed the fully connected layer.\n",
    "        # Output shape: (b, sum(num_filters))\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
    "                         dim=1)\n",
    "        \n",
    "        # Compute logits. Output shape: (b, n_classes)\n",
    "        logits = self.fc(self.dropout(x_fc))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def initilize_model(pretrained_embedding=None,\n",
    "                    freeze_embedding=False,\n",
    "                    vocab_size=None,\n",
    "                    embed_dim=300,\n",
    "                    filter_sizes=[3, 4, 5],\n",
    "                    num_filters=[100, 100, 100],\n",
    "                    num_classes=2,\n",
    "                    dropout=0.5,\n",
    "                    learning_rate=0.01):\n",
    "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
    "\n",
    "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
    "    num_filters need to be of the same length.\"\n",
    "\n",
    "    # Instantiate CNN model\n",
    "    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n",
    "                        freeze_embedding=freeze_embedding,\n",
    "                        vocab_size=vocab_size,\n",
    "                        embed_dim=embed_dim,\n",
    "                        filter_sizes=filter_sizes,\n",
    "                        num_filters=num_filters,\n",
    "                        num_classes=num_classes,\n",
    "                        dropout=0.5)\n",
    "    \n",
    "    # Send model to `device` (GPU/CPU)\n",
    "    cnn_model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    criterion=criterion.to(device)\n",
    "\n",
    "    # Instantiate Adadelta optimizer\n",
    "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               rho=0.95)\n",
    "\n",
    "    return cnn_model, optimizer, criterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, optimizer,criterion, train_dataloader, val_dataloader=None, epochs=10):\n",
    "    \"\"\"Train the CNN model.\"\"\"\n",
    "    \n",
    "    # Tracking best validation accuracy\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "    countdown=epochs\n",
    "    for countdown>0:\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "\n",
    "        # Tracking time and loss\n",
    "        t0_epoch = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Load batch to GPU\n",
    "            \n",
    "            b_input_ids, b_labels = tuple(t.to(device).long() for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = criterion(logits, b_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if val_dataloader is not None:\n",
    "            # After the completion of each training epoch, measure the model's\n",
    "            # performance on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader,criterion)\n",
    "\n",
    "            # Track the best accuracy\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "                countdown=epochs\n",
    "            else:\n",
    "                countdown=countdown-1\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "    return best_accuracy\n",
    "\n",
    "def evaluate(model, val_dataloader,criterion):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
    "    # during the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels = tuple(t.to(device).long() for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, max_len=62):\n",
    "    \"\"\"Predict probability that a review is positive.\"\"\"\n",
    "    labels=[]\n",
    "    # Tokenize, pad and encode text\n",
    "    for sent in text:\n",
    "        model.eval()\n",
    "        tokenized=tokenizer_porter(strip_accents(preprocessor(sent)))\n",
    "        if len(tokenized) < min_len:\n",
    "            tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "        indexed = [word2idx.get(token, word2idx['<unk>']) for token in tokenized]\n",
    "         \n",
    "        tensor = torch.LongTensor(indexed).to(device)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        preds = model(tensor)\n",
    "        max_preds = preds.argmax(dim = 1)\n",
    "        label.append(max_preds.item())\n",
    "    return labels\n",
    "def predictTen(text, model, max_len=62):\n",
    "    \"\"\"Predict probability that a review is positive.\"\"\"\n",
    "    labels=[]\n",
    "    # Tokenize, pad and encode text\n",
    "    for input_id in text:\n",
    "        \n",
    "        input_id = torch.tensor(input_id).to(device).unsqueeze(dim=0)\n",
    "        # Compute logits\n",
    "        logits = model.forward(input_id)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        #  Compute probability\n",
    "        labels.append(preds.item())\n",
    "        #  Compute probability\n",
    "        \n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   2.904353   |  2.840939  |   13.62   |  246.63  \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 13.62%.\n",
      "--------------- Fold:  1 ---------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       210\n",
      "           2       0.00      0.00      0.00        72\n",
      "           3       0.00      0.00      0.00       202\n",
      "           4       0.00      0.00      0.00       102\n",
      "           5       0.00      0.00      0.00       162\n",
      "           6       0.00      0.00      0.00       137\n",
      "           7       0.00      0.00      0.00       119\n",
      "           8       0.00      0.00      0.00        54\n",
      "           9       0.00      0.00      0.00       102\n",
      "          10       0.00      0.00      0.00       252\n",
      "          12       0.14      1.00      0.24       361\n",
      "          13       0.00      0.00      0.00        54\n",
      "          14       0.00      0.00      0.00        36\n",
      "          15       0.00      0.00      0.00       199\n",
      "          16       0.00      0.00      0.00        66\n",
      "          17       0.00      0.00      0.00        51\n",
      "          18       0.00      0.00      0.00        14\n",
      "          19       0.00      0.00      0.00       116\n",
      "          20       0.00      0.00      0.00       242\n",
      "          21       0.00      0.00      0.00        58\n",
      "          23       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.14      2624\n",
      "   macro avg       0.01      0.05      0.01      2624\n",
      "weighted avg       0.02      0.14      0.03      2624\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\berto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fc86a30cfd4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                             dropout=0.5)\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_non_static\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0maccuracys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mcnn_non_static\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tut5-model.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-3cf44fe814f7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;31m# Perform a backward pass to calculate gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\berto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\berto\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "X=input_ids\n",
    "y=y\n",
    "numclass=len(np.unique(y))+3\n",
    "nfold=2\n",
    "kfold = StratifiedKFold(n_splits=nfold).split(input_ids, y)\n",
    "\n",
    "accuracys = []\n",
    "scores= []\n",
    "\n",
    "target_names=list(np.unique(y))\n",
    "\n",
    "for k, (tr, test) in enumerate(kfold):\n",
    "    train_dataloader, val_dataloader =data_loader(X[tr], X[test], y[tr], y[test], batch_size=50)\n",
    "    # CNN-non-static: fastText pretrained word vectors are fine-tuned during training.\n",
    "    \n",
    "    \n",
    "    set_seed(42)\n",
    "    cnn_non_static, optimizer, criterion = initilize_model(pretrained_embedding=embeddings,\n",
    "                                            num_classes=numclass,\n",
    "                                            freeze_embedding=False,\n",
    "                                            learning_rate=0.25,                                            \n",
    "                                            dropout=0.5)\n",
    "    accuracy=train(cnn_non_static, optimizer, criterion, train_dataloader, val_dataloader, epochs=5)\n",
    "    accuracys.append(accuracy)\n",
    "    cnn_non_static.load_state_dict(torch.load('tut5-model.pt'))\n",
    "    y_pred=predictTen(X[test],cnn_non_static,max_len=max_len)\n",
    "    \n",
    "    score=precision_recall_fscore_support(y_true=y[test], y_pred=y_pred, labels=np.unique(y_pred), average=\"weighted\")\n",
    "    scores.append(score[0:3])\n",
    "    print('--------------- Fold: %2d ---------------------'% (k+1))\n",
    "    print()\n",
    "    target_names = list(map(str,target_names))\n",
    "    print(metrics.classification_report(y[test], y_pred, target_names=target_names))\n",
    "    conf_mat = confusion_matrix(y[test], y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "                xticklabels=target_names , yticklabels=target_names )\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    print()\n",
    "\n",
    "arr = np.array(scores)\n",
    "\n",
    "print(\"Overall results of the cross-validation procedure\")\n",
    "print()\n",
    "\n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(accuracys), np.std(accuracys)))\n",
    "print('\\nCV precision: %.3f +/- %.3f' % (np.mean(arr[:,0]), np.std(arr[:,0])))\n",
    "print('\\nCV recall: %.3f +/- %.3f' % (np.mean(arr[:,1]), np.std(arr[:,1])))\n",
    "print('\\nCV f1: %.3f +/- %.3f' % (np.mean(arr[:,2]), np.std(arr[:,2])))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
